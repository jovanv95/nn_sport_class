{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# path to the data\n",
    "\n",
    "train_data_path = './data/train'\n",
    "test_data_path = './data/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('./data/train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform for mean and std\n",
    "\n",
    "train_trans_ms = transforms.Compose([transforms.ToTensor(),transforms.Resize((225,255))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying transformation and selecting the data \n",
    "\n",
    "train_dataset_ms = torchvision.datasets.ImageFolder(root = train_data_path , transform= train_trans_ms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset, need to do so in batches or else we run out of RAM\n",
    "\n",
    "train_loader_ms = torch.utils.data.DataLoader(dataset = train_dataset_ms, batch_size = 32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating std and mean\n",
    "\n",
    "def get_mean_and_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_img_count = 0\n",
    "    # looping thrue each batch\n",
    "    for images, _ in loader:\n",
    "        # number of images in batch\n",
    "        images_count_in_batch = images.size(0)\n",
    "        # resizeing the image tensor in the batch in order to reduce the dimensions of the tensor form 4 to 3\n",
    "        images = images.view(images_count_in_batch, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_img_count += images_count_in_batch\n",
    "\n",
    "    mean /= total_img_count\n",
    "    std /= total_img_count\n",
    "\n",
    "# return a proxy mean and std , we cant get the real one because we cant load the whole data set, so we calculate the avrage for each batch and then the avrage for all the batches \n",
    "    return mean,std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the mean and std\n",
    "\n",
    "mean , std = get_mean_and_std(train_loader_ms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans = transforms.Compose([transforms.ToTensor(), transforms.RandomHorizontalFlip(),transforms.RandomRotation(10),transforms.Normalize(mean,std),transforms.Resize((225,225))])\n",
    "\n",
    "test_trans = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean,std),transforms.Resize((225,225))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root = train_data_path, transform=train_trans)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root = test_data_path, transform=test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_trans_img(dataset):\n",
    "    loader = torch.utils.data.DataLoader(dataset,batch_size = 6,shuffle=True)\n",
    "    batch = next(iter(loader))\n",
    "    Images,lables = batch\n",
    "    grid = torchvision.utils.make_grid(Images,nrow=3)\n",
    "    plt.figure(figsize=(11,11))\n",
    "    plt.imshow(np.transpose(grid,(1,2,0)))\n",
    "    print('lables:', lables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=64,shuffle=False,pin_memory=True,num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=64,shuffle=False,pin_memory=True,num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        dev = 'cuda:0'\n",
    "    else:\n",
    "        dev = 'cpu'\n",
    "    return torch.device(dev)\n",
    "\n",
    "set_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#chose a model, but set weights to None so you can train it yourself\n",
    "resnet_18_model = models.resnet18(weights=None)\n",
    "\n",
    "num_ftrs = resnet_18_model.fc.in_features\n",
    "number_of_classes = len(os.listdir('./data/train'))\n",
    "resnet_18_model.fc = nn.Linear(num_ftrs,number_of_classes)\n",
    "device = set_device()\n",
    "resnet_18_model = resnet_18_model.to('cuda')\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# lr 0.01 to 0.1 experminet whit it\n",
    "# momenntum makes gradient desecnt faster\n",
    "# weight_decay extra error to loss function , prevents overfiting\n",
    "optimizer = optim.SGD(resnet_18_model.parameters(),lr=0.01,momentum=0.9,weight_decay=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test_set(model,test_loader):\n",
    "    model.eval()\n",
    "    predicted_correctly_on_epoch = 0\n",
    "    total = 0\n",
    "    device =set_device()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images , lables = data\n",
    "            images = images.to(device)\n",
    "            lables = lables.to(device)\n",
    "            total += lables.size(0)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _ , predicted = torch.max(outputs.data,1)\n",
    "\n",
    "            predicted_correctly_on_epoch += (predicted == lables).sum().item()\n",
    "    \n",
    "    epoch_acc = 100.0 * predicted_correctly_on_epoch / total\n",
    "    print('     -Test dataset. Got %d out of %d images correctly(%.3f%%)' % (predicted_correctly_on_epoch,total, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state,filename = 'model_checkpoint.pth.tar'):\n",
    "    print('=> Saveing checkpoint')\n",
    "    torch.save(state,filename,_use_new_zipfile_serialization=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint):\n",
    "    print('=> Loading checkpoint')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['state_dict'])\n",
    "    epoch.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model,train_loader,test_loader,criterion,optimizer,n_epoch):\n",
    "    device = set_device()\n",
    "    for epoch in range(n_epoch):\n",
    "        print('Epoch number %d' % (epoch + 1))\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        total = 0\n",
    "        checkpoint = {'state_dict' : model.state_dict(), 'optimizer': optimizer.state_dict(), 'epoch': epoch}\n",
    "        save_checkpoint(checkpoint)\n",
    "        for data in train_loader:\n",
    "            images , lables = data\n",
    "            images = images.to('cuda',non_blocking=True)\n",
    "            lables = lables.to('cuda',non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs,lables)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        evaluate_model_on_test_set(model,test_loader)\n",
    "        \n",
    "    print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 1\n",
      "=> Saveing checkpoint\n",
      "     -Test dataset. Got 7 out of 157 images correctly(4.459%)\n",
      "Epoch number 2\n",
      "=> Saveing checkpoint\n",
      "     -Test dataset. Got 4 out of 157 images correctly(2.548%)\n",
      "Epoch number 3\n",
      "=> Saveing checkpoint\n",
      "     -Test dataset. Got 1 out of 157 images correctly(0.637%)\n",
      "Epoch number 4\n",
      "=> Saveing checkpoint\n",
      "     -Test dataset. Got 2 out of 157 images correctly(1.274%)\n",
      "Epoch number 5\n",
      "=> Saveing checkpoint\n",
      "     -Test dataset. Got 9 out of 157 images correctly(5.732%)\n",
      "Epoch number 6\n",
      "=> Saveing checkpoint\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_nn(resnet_18_model,train_loader,test_loader,loss_fn,optimizer,\u001b[39m50\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[53], line 11\u001b[0m, in \u001b[0;36mtrain_nn\u001b[1;34m(model, train_loader, test_loader, criterion, optimizer, n_epoch)\u001b[0m\n\u001b[0;32m      9\u001b[0m checkpoint \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m : model\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m'\u001b[39m: optimizer\u001b[39m.\u001b[39mstate_dict(), \u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m: epoch}\n\u001b[0;32m     10\u001b[0m save_checkpoint(checkpoint)\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     12\u001b[0m     images , lables \u001b[39m=\u001b[39m data\n\u001b[0;32m     13\u001b[0m     images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m,non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1317\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1319\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1272\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1270\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m   1271\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[1;32m-> 1272\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1273\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1274\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1108\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1109\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1117\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1120\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1121\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1122\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1123\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\torch\\lib\\threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    315\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    317\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_nn(resnet_18_model,train_loader,test_loader,loss_fn,optimizer,50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3b09f0dae079356b11e2992c8ce1698bd60fda55aea4c87f004ec164747e9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
